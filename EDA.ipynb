{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from potosnail import Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\aacjp\\Sales-Scientist\\datasets\\MockHyros.csv')\n",
    "df2 = pd.read_csv(r'C:\\Users\\aacjp\\Sales-Scientist\\datasets\\HyrosAugmented.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What range accuratley represents the closing rate? In more technical terms, what is the 95% confidence interval?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3727584770115503, 0.7405748563217828)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getCI(x, samples, n, std_range=2):\n",
    "    '''get the confidence interval for the average value in a population'''\n",
    "    Xbars = []\n",
    "    for i in range(samples):\n",
    "        sample = random.sample(x, n)\n",
    "        Xbars.append(np.mean(sample))\n",
    "    variance = np.std(Xbars)*2\n",
    "    mu = np.mean(Xbars)\n",
    "    return (mu-variance, mu+variance)\n",
    "\n",
    "output = getCI(list(df2['closed']), 10, 30) \n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are 95% sure that between 37% and 74% of our leads close\n"
     ]
    }
   ],
   "source": [
    "print('We are 95% sure that between {}% and {}% of our leads close'.format(round(output[0]*100), round(output[1]*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Establish relevance to Hyros growth goals (find them)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333333333333334"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ProbsClosing(df, revenue, domain, business_model, margin=0.1):\n",
    "    minimum = revenue - margin*revenue\n",
    "    maximum = revenue + margin*revenue\n",
    "    greater = df.loc[df['monthly revenue']>minimum]\n",
    "    lesser = greater.loc[greater['monthly revenue']<maximum]\n",
    "    domain = lesser.loc[lesser['domain']==domain]\n",
    "    bm = domain.loc[domain['business model']==business_model]\n",
    "    closed = len(bm.loc[bm['closed']==1])\n",
    "    try:\n",
    "        return closed/len(bm)\n",
    "    except:\n",
    "        return 'sorry not enough data available'\n",
    "\n",
    "ProbsClosing(df, 500000, 'marketing', 'consulting', margin=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ProbsClosing2(df, revenue, domain, business_model, margin=0.1):\n",
    "    minimum = revenue - margin*revenue\n",
    "    maximum = revenue + margin*revenue\n",
    "    greater = df.loc[df['monthly revenue']>minimum]\n",
    "    lesser = greater.loc[greater['monthly revenue']<maximum]\n",
    "    domain = lesser.loc[lesser[domain]==1]\n",
    "    bm = domain.loc[domain[business_model]==1]\n",
    "    closed = len(bm.loc[bm['closed']==1])\n",
    "    try:\n",
    "        return closed/len(bm)\n",
    "    except:\n",
    "        return 'sorry not enough data available'\n",
    "\n",
    "ProbsClosing2(df2, 500000, 'ecommerce', 'software', margin=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "1015    0\n",
       "1016    0\n",
       "1017    1\n",
       "1018    1\n",
       "1019    0\n",
       "Name: marketing, Length: 1020, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['marketing']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for signifigant difference in adspend based on the lead's business models and whether or not they closed. AKA Chai-Squared Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reverse one hot encoding and use bigger dataset for better results\n",
    "sample_from = df[['monthly traffic spend', 'closed', 'business model']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = sample_from.sample(n=30)\n",
    "s2 = sample_from.sample(n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009481481481481481"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chaiSquare(sample, cat_feat1, cat_feat2):\n",
    "    values1 = list(np.unique(sample[cat_feat1]))\n",
    "    n1 = len(values1)\n",
    "    E1 = len(sample)/n1\n",
    "    resE1 = 0\n",
    "    for v in values1:\n",
    "        o = len(sample.loc[sample[cat_feat1]==v])\n",
    "        res = (o - E1)**2 / E1\n",
    "        res2 = res**2\n",
    "        resE1 += res2/E1\n",
    "    return resE1\n",
    "\n",
    "chaiSquare(s1, 'closed', 'business model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
